{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a018d1d2-81e9-4f82-88f3-8f106331afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da005825-5f69-4385-b909-c0f2aab581e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(\"demo/yolov4-tiny.cfg\", \"demo/yolov4-tiny.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad6097d-6e11-4ecd-bb95-690890ea728f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conv_0',\n",
       " 'bn_0',\n",
       " 'leaky_1',\n",
       " 'conv_1',\n",
       " 'bn_1',\n",
       " 'leaky_2',\n",
       " 'conv_2',\n",
       " 'bn_2',\n",
       " 'leaky_3',\n",
       " 'slice_3',\n",
       " 'conv_4',\n",
       " 'bn_4',\n",
       " 'leaky_5',\n",
       " 'conv_5',\n",
       " 'bn_5',\n",
       " 'leaky_6',\n",
       " 'concat_6',\n",
       " 'conv_7',\n",
       " 'bn_7',\n",
       " 'leaky_8',\n",
       " 'concat_8',\n",
       " 'pool_9',\n",
       " 'conv_10',\n",
       " 'bn_10',\n",
       " 'leaky_11',\n",
       " 'slice_11',\n",
       " 'conv_12',\n",
       " 'bn_12',\n",
       " 'leaky_13',\n",
       " 'conv_13',\n",
       " 'bn_13',\n",
       " 'leaky_14',\n",
       " 'concat_14',\n",
       " 'conv_15',\n",
       " 'bn_15',\n",
       " 'leaky_16',\n",
       " 'concat_16',\n",
       " 'pool_17',\n",
       " 'conv_18',\n",
       " 'bn_18',\n",
       " 'leaky_19',\n",
       " 'slice_19',\n",
       " 'conv_20',\n",
       " 'bn_20',\n",
       " 'leaky_21',\n",
       " 'conv_21',\n",
       " 'bn_21',\n",
       " 'leaky_22',\n",
       " 'concat_22',\n",
       " 'conv_23',\n",
       " 'bn_23',\n",
       " 'leaky_24',\n",
       " 'concat_24',\n",
       " 'pool_25',\n",
       " 'conv_26',\n",
       " 'bn_26',\n",
       " 'leaky_27',\n",
       " 'conv_27',\n",
       " 'bn_27',\n",
       " 'leaky_28',\n",
       " 'conv_28',\n",
       " 'bn_28',\n",
       " 'leaky_29',\n",
       " 'conv_29',\n",
       " 'permute_30',\n",
       " 'yolo_30',\n",
       " 'identity_31',\n",
       " 'conv_32',\n",
       " 'bn_32',\n",
       " 'leaky_33',\n",
       " 'upsample_33',\n",
       " 'concat_34',\n",
       " 'conv_35',\n",
       " 'bn_35',\n",
       " 'leaky_36',\n",
       " 'conv_36',\n",
       " 'permute_37',\n",
       " 'yolo_37')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_names = net.getLayerNames()\n",
    "layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2523c158-7c70-4244-af63-f00cc03406e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 78], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_layers_indexes = net.getUnconnectedOutLayers()\n",
    "out_layers_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837043d9-7bee-4e45-9506-890a22aa35f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolo_30', 'yolo_37']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_layers = [layer_names[index - 1] for index in out_layers_indexes]\n",
    "out_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f535f8e4-bfc6-4561-9cb6-5c7c18b422ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorbike',\n",
       " 'aeroplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'sofa',\n",
       " 'pottedplant',\n",
       " 'bed',\n",
       " 'diningtable',\n",
       " 'toilet',\n",
       " 'tvmonitor',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"demo/coco.names.txt\") as file:\n",
    "    classes = file.read().split(\"\\n\")\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f4efc0-59ea-42fc-bdc9-9f5746a31374",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_look_for = [\"truck\", \"person\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c240ec2-629b-434d-a1f2-4b084e8175ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def draw_object_bounding_box(image_to_process, index, box):\n",
    "    \"\"\"\n",
    "    Рисование границ объекта с подписями\n",
    "    :param image_to_process: исходное изображение\n",
    "    :param index: индекс определённого с помощью YOLO класса объекта\n",
    "    :param box: координаты области вокруг объекта\n",
    "    :return: изображение с отмеченными объектами\n",
    "    \"\"\"\n",
    "    x, y, w, h = box\n",
    "    start = (x, y)\n",
    "    end = (x + w, y + h)\n",
    "    color = (0, 255, 0)\n",
    "    width = 2\n",
    "    final_image = cv2.rectangle(image_to_process, start, end, color, width)\n",
    "\n",
    "    start = (x, y - 10)\n",
    "    font_size = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    width = 2\n",
    "    text = classes[index]\n",
    "    final_image = cv2.putText(final_image, text, start, font, font_size, color, width, cv2.LINE_AA)\n",
    "\n",
    "    return final_image\n",
    "\n",
    "\n",
    "def draw_object_count(image_to_process, objects_count):\n",
    "    \"\"\"\n",
    "    Подпись количества найденных объектов на изображении\n",
    "    :param image_to_process: исходное изображение\n",
    "    :param objects_count: количество объектов искомого класса\n",
    "    :return: изображение с подписаным количеством найденных объектов\n",
    "    \"\"\"\n",
    "\n",
    "    start = (45, 150)\n",
    "    font_size = 1.5\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    width = 3\n",
    "    text = \"Objects found: \" + str(objects_count)\n",
    "\n",
    "    # вывод текста с обводкой (чтобы было видно при разном освещении картинки)\n",
    "    white_color = (255, 255, 255)\n",
    "    black_outline_color = (0, 0, 0)\n",
    "    final_image = cv2.putText(image_to_process, text, start, font, font_size, black_outline_color, width * 3, cv2.LINE_AA)\n",
    "    final_image = cv2.putText(final_image, text, start, font, font_size, white_color, width, cv2.LINE_AA)\n",
    "\n",
    "    return final_image\n",
    "\n",
    "\n",
    "def apply_yolo_object_detection(image_to_process):\n",
    "    \"\"\"\n",
    "    Распознавание и определение координат объектов на изображении\n",
    "    :param image_to_process: исходное изображение\n",
    "    :return: изображение с размеченными объектами и подписями к ним\n",
    "    \"\"\"\n",
    "    height, width, depth = image_to_process.shape\n",
    "    blob = cv2.dnn.blobFromImage(image_to_process, 1 / 255, (608, 608), (0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(out_layers)\n",
    "\n",
    "    print(outs)\n",
    "    print(len(outs))\n",
    "    for x in outs:\n",
    "        print(len(x))\n",
    "\n",
    "    class_indexes, class_scores, boxes = ([] for i in range(3))\n",
    "    objects_count = 0\n",
    "\n",
    "    # запуск поиска объектов на изображении\n",
    "    for out in outs:\n",
    "        for obj in out:\n",
    "            scores = obj[5:]\n",
    "            class_index = np.argmax(scores)\n",
    "            class_score = scores[class_index]\n",
    "            if class_score > 0:\n",
    "                center_x = int(obj[0] * width)\n",
    "                center_y = int(obj[1] * height)\n",
    "                obj_width = int(obj[2] * width)\n",
    "                obj_height = int(obj[3] * height)\n",
    "\n",
    "                box = [center_x - obj_width // 2, center_y - obj_height // 2, obj_width, obj_height]\n",
    "                boxes.append(box)\n",
    "                class_indexes.append(class_index)\n",
    "                class_scores.append(float(class_score))\n",
    "\n",
    "    # проведение выборки\n",
    "    chosen_boxes = cv2.dnn.NMSBoxes(boxes, class_scores, 0.0, 0.4)\n",
    "\n",
    "    print(chosen_boxes)\n",
    "    print(class_indexes)\n",
    "\n",
    "    for box_index in chosen_boxes:\n",
    "        box_index = box_index\n",
    "        box = boxes[box_index]\n",
    "        class_index = class_indexes[box_index]\n",
    "\n",
    "        # debug-рисование объектов, входящих в искомые классы\n",
    "        if classes[class_index] in classes_to_look_for:\n",
    "            objects_count += 1\n",
    "            image_to_process = draw_object_bounding_box(image_to_process, class_index, box)\n",
    "\n",
    "    final_image = draw_object_count(image_to_process, objects_count)\n",
    "\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7750cf23-bdf2-419f-8704-0597384d142c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.04078696, 0.03125866, 0.11186892, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.03703755, 0.02410808, 0.12978752, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.02969689, 0.02501762, 0.47472197, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.961629  , 0.9700703 , 0.13243048, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.96200985, 0.95834273, 0.1637088 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9695973 , 0.95818186, 0.36141846, ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32), array([[0.01262581, 0.01154043, 0.04110672, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.01351764, 0.02039025, 0.05433187, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.01111054, 0.01947958, 0.1707725 , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.9861131 , 0.9834872 , 0.03457957, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9842321 , 0.9777325 , 0.04478522, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.9877017 , 0.98137283, 0.19262208, ..., 0.        , 0.        ,\n",
      "        0.        ]], dtype=float32))\n",
      "2\n",
      "1083\n",
      "4332\n",
      "[7 8 1 5 0 2]\n",
      "[7, 7, 67, 7, 7, 45, 7, 7, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "    try:\n",
    "        # применение методов распознавания объектов на изображении от YOLO\n",
    "        image = cv2.imread(\"demo/assets/truck_captcha.png\")\n",
    "        image = apply_yolo_object_detection(image)\n",
    "\n",
    "        # # вывод обработанного изображения на экран\n",
    "        # cv2.imshow(\"Image\", image)\n",
    "        # if cv2.waitKey(0):\n",
    "        #     cv2.destroyAllWindows()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ece80d-354f-40ea-9bff-d9d7b56a04ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
